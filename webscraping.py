# -*- coding: utf-8 -*-
"""webscraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QRgAk7ZeyeoG9HPVYIiSYPdg07hknluf
"""

import requests
from bs4 import BeautifulSoup
import re
import csv

for count in range(4000):

 url = 'https://www.wikihow.com/Special:Randomizer'

 response = requests.get(url)
 html_content = response.content

 soup = BeautifulSoup(html_content, 'html.parser')
 art_title = soup.find('title').text.strip()
 print(art_title+" "+str(count))


 subheading = []
 paragraph = []
 steps = soup.find_all('div', class_='step')
 for step in steps:
    subheading_element = step.find('b')
    if(subheading_element is not None):
        subheading_text = subheading_element.text.strip().replace('\n', '')
        subheading_text = subheading_text.encode('ascii', 'ignore').decode('ascii')
        subheading_text = re.sub(r'\s+', ' ', subheading_text)
        subheading.append(subheading_text)
        subheading_element.extract()
        for span_tag in step.find_all('span'):
            span_tag.extract()
        paragraph_text = step.text.strip().replace('\n', '')
        paragraph_text = paragraph_text.encode('ascii', 'ignore').decode('ascii')
        paragraph_text = re.sub(r'\s+', ' ', paragraph_text)
        paragraph.append(paragraph_text)

 if(len(subheading)):
   with open('wikihow.csv', 'w', newline='', encoding='utf-8') as csvfile:
     writer = csv.writer(csvfile)
     for i in range(len(subheading)):
       writer.writerow([art_title,subheading[i], paragraph[i]])

